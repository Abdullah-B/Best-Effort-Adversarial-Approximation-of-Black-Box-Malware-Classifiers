from keras.layers import Dense, Conv1D, Activation, GlobalMaxPooling1D, Input, Embedding, Multiply
from keras.models import Model
from keras import backend as K
from keras import metrics
import multi_gpu
import os
import math
import random
import argparse
import os
import sys
import numpy as np
import pandas as pd
from keras.models import load_model

#################################################################
batch_size = 100
input_dim = 257 # every byte plus a special padding symbol
padding_char = 256

parser = argparse.ArgumentParser()
parser.add_argument('--gpus', help='number of GPUs', default=1) #### set up and reloading the Black Box modle (malconv 93%)

args = parser.parse_args()
ngpus = int(args.gpus)
basemodel = load_model('malconv.h5')
_, maxlen, embedding_size = basemodel.layers[1].output_shape
input_dim
####################################################################

def bytez_to_numpy(bytez,maxlen):
        
        b = np.ones( (maxlen,), dtype=np.uint16 )*padding_char
        bytez = np.frombuffer( bytez[:maxlen], dtype=np.uint8 )
        b[:len(bytez)] = bytez
        return b

def getfile_service(sha256,lbl,maxlen=maxlen, ): 

    with open(sha256,"rb") as f: 
        header =f.read()
                    
    return bytez_to_numpy( header, maxlen )        

def generator( hashes, labels, batch_size, shuffle=True ):
    X = []
    y = []
    N = []
    zipped = list(zip(hashes, labels))
    while True:
        if shuffle:
            random.shuffle( zipped )
        for sha256,l in zipped:
            
            try:
                x = getfile_service(sha256,l,maxlen)
                if x is None:
                    continue
                X.append( x )
                y.append( l )
                N.append(sha256)
                if len(X) == batch_size:
                    yield np.asarray(X,dtype=np.uint16), np.asarray(y), np.asarray(N)
                    X = []
                    y = []
            except:
                print('***')
                print(sha256)
                continue


train_labelsM = pd.read_csv('Tables/TrainingSet_Aprox.csv', index_col=False) #FileNames_revised.csv

labels = train_labelsM['y'].tolist()
hashes = train_labelsM['FilesNames'].tolist()

print('getting names and lables')
#predictor = generator(hashes,labels,batch_size=1,shuffle=False)
zipped = list(zip(hashes, labels))
df = pd.DataFrame(columns =['FileName', 'Actual','Predicted'])
#BB_p = basemodel.predict_generator( predictor, steps=len(test_labels), verbose=1 )




for sha256,l in zipped:
         
    #try:

    x = getfile_service(sha256,l,maxlen)
    print('got x')
    FN= sha256
    lbl_a = l
    print('got name and lable')
    X=[]
    X.append(x)
    X = np.asarray(X,dtype=np.uint16)
    BB_p= basemodel.predict(X) ## BB_p black box prediction, lbl_a actual lable , FN File Name
    print(BB_p)
    print('got that')
    if BB_p < 0.5:
        row = {'FileName' : FN, 'Actual' :  lbl_a,'Predicted' : 0}
    else:
        row = {'FileName' : FN, 'Actual' : lbl_a, 'Predicted' : 1}
    df = df.append(row, ignore_index=True)
    print(row)
    #except:
        #print('something faile')


df.to_csv('Tables/PredictFromBB.csv')


    
    
        



